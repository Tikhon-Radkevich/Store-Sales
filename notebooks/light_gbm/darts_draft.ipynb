{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfb392d4e80626f9",
   "metadata": {},
   "source": "## Notebook Configuration && Imports"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "997929215ba9afd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:31:20.293938Z",
     "start_time": "2024-10-25T12:31:20.281323Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bc8a8e87a096779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:31:27.438307Z",
     "start_time": "2024-10-25T12:31:20.516205Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models import LightGBMModel\n",
    "\n",
    "from storesales.light_gbm.preprocessing import preprocess\n",
    "from storesales.light_gbm.utils import save_submission\n",
    "from storesales.light_gbm.loss import clipped_rmsle\n",
    "from storesales.constants import (\n",
    "    EXTERNAL_TRAIN_PATH,\n",
    "    EXTERNAL_TEST_PATH,\n",
    "    TRAIN_TEST_SPLIT_DATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d606d34b933926f5",
   "metadata": {},
   "source": "## Load Data"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1c3cb731b0f89d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:31:29.226667Z",
     "start_time": "2024-10-25T12:31:27.439796Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(EXTERNAL_TRAIN_PATH, parse_dates=[\"date\"])\n",
    "test_df = pd.read_csv(EXTERNAL_TEST_PATH, parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8699e569c1577b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:31:29.284568Z",
     "start_time": "2024-10-25T12:31:29.227768Z"
    }
   },
   "outputs": [],
   "source": [
    "train_end = train_df[\"date\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b84b616242280b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:31:37.626345Z",
     "start_time": "2024-10-25T12:31:29.286509Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessed_df = preprocess(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce14eb86b39f108f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:31:37.808394Z",
     "start_time": "2024-10-25T12:31:37.627835Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessed_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d426b4f35764309b",
   "metadata": {},
   "source": "## Prepare Data Before Making Series"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aabb4864c8c0f56a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:31:44.730615Z",
     "start_time": "2024-10-25T12:31:44.607642Z"
    }
   },
   "outputs": [],
   "source": [
    "train_columns = [\"date\", \"sales\", \"onpromotion\", \"store_nbr\", \"family\"]\n",
    "\n",
    "train_test_df = pd.concat([preprocessed_df, test_df], axis=0, ignore_index=True)\n",
    "train_data = train_test_df[train_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac7180b3bcec5b5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:31:45.886654Z",
     "start_time": "2024-10-25T12:31:45.339762Z"
    }
   },
   "outputs": [],
   "source": [
    "# ensure that I have enough data to get lags\n",
    "\n",
    "threshold_date = pd.Timestamp(\"2017-04-01\")\n",
    "\n",
    "min_dates = train_data.groupby([\"family\", \"store_nbr\"])[\"date\"].min().reset_index()\n",
    "valid_groups = min_dates[min_dates[\"date\"] <= threshold_date]\n",
    "\n",
    "lgb_train_data = pd.merge(\n",
    "    train_data,\n",
    "    valid_groups[[\"family\", \"store_nbr\"]],\n",
    "    on=[\"family\", \"store_nbr\"],\n",
    "    how=\"inner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c16cd41c56abf0",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "Some store-family pairs do not have enough data to get lags. I will use the mean sales as the prediction for these pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1f35707fc442035",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:32:02.258684Z",
     "start_time": "2024-10-25T12:32:01.930778Z"
    }
   },
   "outputs": [],
   "source": [
    "not_valid_groups = min_dates[min_dates[\"date\"] > threshold_date]\n",
    "\n",
    "baseline_train_data = pd.merge(\n",
    "    train_df,\n",
    "    not_valid_groups[[\"family\", \"store_nbr\"]],\n",
    "    on=[\"family\", \"store_nbr\"],\n",
    "    how=\"inner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a74c38443001d1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:37:10.431597Z",
     "start_time": "2024-10-25T12:37:10.313608Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_sales_df = (\n",
    "    baseline_train_data.sort_values(by=\"date\")\n",
    "    .groupby([\"store_nbr\", \"family\"])[\"sales\"]\n",
    "    .apply(lambda x: x.tail(14).mean())\n",
    "    .reset_index(name=\"sales\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5d2593ddead7aab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:37:26.348409Z",
     "start_time": "2024-10-25T12:37:26.286071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>LADIESWEAR</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>9.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>4425.214286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_nbr      family        sales\n",
       "0          6   BABY CARE     0.000000\n",
       "1         22  LADIESWEAR     0.214286\n",
       "2         52  AUTOMOTIVE    12.500000\n",
       "3         52      BEAUTY     9.785714\n",
       "4         52   BEVERAGES  4425.214286"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5efd48f8f440d4",
   "metadata": {},
   "source": "## Prepare Series"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43f4ac33a75f2b99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:32:06.127895Z",
     "start_time": "2024-10-25T12:32:06.072969Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_series_and_id_dicts(df: pd.DataFrame):\n",
    "    series_dict = {}\n",
    "    series_id_dict = {}\n",
    "\n",
    "    for family in df[\"family\"].unique():\n",
    "        series = TimeSeries.from_group_dataframe(\n",
    "            df=df[df[\"family\"] == family],\n",
    "            time_col=\"date\",\n",
    "            value_cols=\"sales\",\n",
    "            group_cols=\"store_nbr\",\n",
    "            static_cols=None,\n",
    "        )\n",
    "        series_id = [\n",
    "            {\"store_nbr\": s.static_covariates.store_nbr.iloc[0], \"family\": family}\n",
    "            for s in series\n",
    "        ]\n",
    "        series_id_dict[family] = series_id\n",
    "\n",
    "        series = [s.with_static_covariates(None) for s in series]\n",
    "\n",
    "        series_dict[family] = series\n",
    "\n",
    "    return series_dict, series_id_dict\n",
    "\n",
    "\n",
    "def get_future_covariates_dict(df: pd.DataFrame):\n",
    "    future_dict = {}\n",
    "\n",
    "    for family in df[\"family\"].unique():\n",
    "        future_covariates = TimeSeries.from_group_dataframe(\n",
    "            df=df[df[\"family\"] == family],\n",
    "            time_col=\"date\",\n",
    "            value_cols=\"onpromotion\",\n",
    "            group_cols=\"store_nbr\",\n",
    "        )\n",
    "        future_dict[family] = [\n",
    "            f.with_static_covariates(None) for f in future_covariates\n",
    "        ]\n",
    "\n",
    "    return future_dict\n",
    "\n",
    "\n",
    "def train_test_split(series: dict[str, list[TimeSeries]], split_date: pd.Timestamp):\n",
    "    train_series = {}\n",
    "\n",
    "    for family, series_list in series.items():\n",
    "        train_series[family] = [s.drop_after(split_date) for s in series_list]\n",
    "\n",
    "    return train_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41f33ff658e3cb77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:32:28.807998Z",
     "start_time": "2024-10-25T12:32:06.431254Z"
    }
   },
   "outputs": [],
   "source": [
    "data_series_dict, data_series_id_dict = get_series_and_id_dicts(lgb_train_data)\n",
    "future_covariates_dict = get_future_covariates_dict(lgb_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48145a01b53d9e1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:32:29.814225Z",
     "start_time": "2024-10-25T12:32:28.809564Z"
    }
   },
   "outputs": [],
   "source": [
    "train_series_dict = train_test_split(\n",
    "    data_series_dict, pd.Timestamp(TRAIN_TEST_SPLIT_DATE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1b1911688f49b76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:32:37.666016Z",
     "start_time": "2024-10-25T12:32:37.626377Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_light_gb_models():\n",
    "    light_gb_models = {}\n",
    "\n",
    "    for family, series in data_series_dict.items():\n",
    "        inputs = {\n",
    "            \"series\": [s.drop_after(pd.Timestamp(\"2017-07-10\")) for s in series],\n",
    "            \"future_covariates\": future_covariates_dict[family],\n",
    "        }\n",
    "        light_gb_models[family] = LightGBMModel(\n",
    "            lags=24, lags_future_covariates=(14, 1), force_col_wise=True\n",
    "        )\n",
    "\n",
    "        light_gb_models[family].fit(**inputs)\n",
    "\n",
    "    return light_gb_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d23b414c133be33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:32:55.337237Z",
     "start_time": "2024-10-25T12:32:40.480039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2487\n",
      "[LightGBM] [Info] Number of data points in the train set: 81055, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 6.600093\n",
      "[LightGBM] [Info] Total Bins 6150\n",
      "[LightGBM] [Info] Number of data points in the train set: 47003, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 0.724151\n",
      "[LightGBM] [Info] Total Bins 3281\n",
      "[LightGBM] [Info] Number of data points in the train set: 81047, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.016515\n",
      "[LightGBM] [Info] Total Bins 7931\n",
      "[LightGBM] [Info] Number of data points in the train set: 81057, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 2574.898948\n",
      "[LightGBM] [Info] Total Bins 5625\n",
      "[LightGBM] [Info] Number of data points in the train set: 51940, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.141593\n",
      "[LightGBM] [Info] Total Bins 7545\n",
      "[LightGBM] [Info] Number of data points in the train set: 81057, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 501.402241\n",
      "[LightGBM] [Info] Total Bins 6345\n",
      "[LightGBM] [Info] Number of data points in the train set: 63815, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 14.236394\n",
      "[LightGBM] [Info] Total Bins 7545\n",
      "[LightGBM] [Info] Number of data points in the train set: 81057, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 1158.035049\n",
      "[LightGBM] [Info] Total Bins 8535\n",
      "[LightGBM] [Info] Number of data points in the train set: 81057, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 770.502449\n",
      "[LightGBM] [Info] Total Bins 7350\n",
      "[LightGBM] [Info] Number of data points in the train set: 81057, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 286.963926\n",
      "[LightGBM] [Info] Total Bins 6615\n",
      "[LightGBM] [Info] Number of data points in the train set: 81057, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 185.714645\n",
      "[LightGBM] [Info] Total Bins 6615\n",
      "[LightGBM] [Info] Number of data points in the train set: 81057, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 169.295754\n",
      "[LightGBM] [Info] Total Bins 8966\n",
      "[LightGBM] [Info] Number of data points in the train set: 81057, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4086.780493\n",
      "[LightGBM] [Info] Total Bins 6239\n",
      "[LightGBM] [Info] Number of data points in the train set: 81057, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 23.133005\n",
      "[LightGBM] [Info] Total Bins 4646\n",
      "[LightGBM] [Info] Number of data points in the train set: 79589, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 1.303144\n",
      "[LightGBM] [Info] Total Bins 6495\n",
      "[LightGBM] [Info] Number of data points in the train set: 63997, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 30.488999\n",
      "[LightGBM] [Info] Total Bins 6360\n",
      "[LightGBM] [Info] Number of data points in the train set: 63995, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 24.096015\n",
      "[LightGBM] [Info] Total Bins 6083\n",
      "[LightGBM] [Info] Number of data points in the train set: 78619, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 0.959548\n",
      "[LightGBM] [Info] Total Bins 6800\n",
      "[LightGBM] [Info] Number of data points in the train set: 63872, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 301.736082\n",
      "[LightGBM] [Info] Total Bins 6360\n",
      "[LightGBM] [Info] Number of data points in the train set: 67303, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 12.121488\n",
      "[LightGBM] [Info] Total Bins 6345\n",
      "[LightGBM] [Info] Number of data points in the train set: 73933, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 7.970156\n",
      "[LightGBM] [Info] Total Bins 3926\n",
      "[LightGBM] [Info] Number of data points in the train set: 81054, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 7.725362\n",
      "[LightGBM] [Info] Total Bins 6435\n",
      "[LightGBM] [Info] Number of data points in the train set: 81057, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 92.456913\n",
      "[LightGBM] [Info] Total Bins 6095\n",
      "[LightGBM] [Info] Number of data points in the train set: 63490, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.430814\n",
      "[LightGBM] [Info] Total Bins 6975\n",
      "[LightGBM] [Info] Number of data points in the train set: 81057, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 369.142463\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 81057, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 292.478552\n",
      "[LightGBM] [Info] Total Bins 6225\n",
      "[LightGBM] [Info] Number of data points in the train set: 63685, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 6.521382\n",
      "[LightGBM] [Info] Total Bins 6360\n",
      "[LightGBM] [Info] Number of data points in the train set: 63808, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 10.618002\n",
      "[LightGBM] [Info] Total Bins 6855\n",
      "[LightGBM] [Info] Number of data points in the train set: 81055, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 381.193984\n",
      "[LightGBM] [Info] Total Bins 6345\n",
      "[LightGBM] [Info] Number of data points in the train set: 81057, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 105.115969\n",
      "[LightGBM] [Info] Total Bins 9867\n",
      "[LightGBM] [Info] Number of data points in the train set: 70856, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 1759.898635\n",
      "[LightGBM] [Info] Total Bins 6315\n",
      "[LightGBM] [Info] Number of data points in the train set: 54558, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 5.391330\n",
      "[LightGBM] [Info] Total Bins 6240\n",
      "[LightGBM] [Info] Number of data points in the train set: 81047, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 24.160189\n"
     ]
    }
   ],
   "source": [
    "models = fit_light_gb_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b6bb08e14e1ffa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:32:57.419750Z",
     "start_time": "2024-10-25T12:32:57.377086Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    end_test = train_end - pd.DateOffset(days=15)\n",
    "    test_period = pd.date_range(start=TRAIN_TEST_SPLIT_DATE, end=end_test, freq=\"D\")\n",
    "\n",
    "    losses = []\n",
    "    for family, series in data_series_dict.items():\n",
    "        family_losses = []\n",
    "        for test_date in tqdm(test_period):\n",
    "            inputs = {\n",
    "                \"series\": [s.drop_after(test_date) for s in series],\n",
    "                \"future_covariates\": future_covariates_dict[family],\n",
    "            }\n",
    "\n",
    "            preds = models[family].predict(n=16, **inputs)\n",
    "\n",
    "            true_values = [s.slice_intersect(p) for p, s in zip(preds, series)]\n",
    "\n",
    "            loss = np.mean(\n",
    "                [\n",
    "                    clipped_rmsle(t.values(), p.values())\n",
    "                    for t, p in zip(true_values, preds)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            family_losses.append(loss)\n",
    "\n",
    "        family_loss = np.mean(family_losses)\n",
    "        print(f\"Family: {family}, Loss: {family_loss}\")\n",
    "        losses.append(family_loss)\n",
    "\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6762db7c62df5831",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc07825e6c9ed3e",
   "metadata": {},
   "source": "## Submission"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3514f2369af2f52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:37:35.231825Z",
     "start_time": "2024-10-25T12:37:35.186726Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df_copy = test_df.copy()\n",
    "test_df_copy.sort_values(by=[\"date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e00af8c082cea69c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:37:35.386439Z",
     "start_time": "2024-10-25T12:37:35.331790Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df_copy = test_df_copy.merge(mean_sales_df, on=[\"store_nbr\", \"family\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63ae6183f54a91ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:37:35.853467Z",
     "start_time": "2024-10-25T12:37:35.803356Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_predictions():\n",
    "    sub_date = pd.Timestamp(train_end)\n",
    "\n",
    "    for family, series in tqdm(data_series_dict.items()):\n",
    "        inputs = {\n",
    "            \"series\": [s.drop_after(sub_date) for s in series],\n",
    "            \"future_covariates\": future_covariates_dict[family],\n",
    "        }\n",
    "        pred = models[family].predict(n=16, **inputs)\n",
    "\n",
    "        for i, values in enumerate(pred):\n",
    "            store_nbr = data_series_id_dict[family][i][\"store_nbr\"]\n",
    "            con = (test_df_copy[\"store_nbr\"] == store_nbr) & (\n",
    "                test_df_copy[\"family\"] == family\n",
    "            )\n",
    "            test_df_copy.loc[con, \"sales\"] = values.values()\n",
    "\n",
    "    return test_df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7b4c6e0871fe101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:37:45.471887Z",
     "start_time": "2024-10-25T12:37:37.088524Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:08<00:00,  3.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "date           0\n",
       "store_nbr      0\n",
       "family         0\n",
       "onpromotion    0\n",
       "sales          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = make_predictions()\n",
    "\n",
    "prediction.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fdfe9b0234905c",
   "metadata": {},
   "source": "## Save Submission"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "674ef1e1a0ea20cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:38:02.849902Z",
     "start_time": "2024-10-25T12:38:02.713098Z"
    }
   },
   "outputs": [],
   "source": [
    "save_submission(prediction, \"light_gbm_with_14_days_mean_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4be282f4b052aff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T12:38:03.349980Z",
     "start_time": "2024-10-25T12:38:03.298338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000888</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>4.985630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3002082</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>42</td>\n",
       "      <td>CELEBRATION</td>\n",
       "      <td>0</td>\n",
       "      <td>8.275210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3002081</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>42</td>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>12</td>\n",
       "      <td>466.089294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3002080</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>42</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.971789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3002079</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>42</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>19</td>\n",
       "      <td>1988.141171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       date  store_nbr        family  onpromotion        sales\n",
       "0  3000888 2017-08-16          1    AUTOMOTIVE            0     4.985630\n",
       "1  3002082 2017-08-16         42   CELEBRATION            0     8.275210\n",
       "2  3002081 2017-08-16         42  BREAD/BAKERY           12   466.089294\n",
       "3  3002080 2017-08-16         42         BOOKS            0     0.971789\n",
       "4  3002079 2017-08-16         42     BEVERAGES           19  1988.141171"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ecc77345b2c228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
